name: Test Zig YAML Parser

on:
  pull_request:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'build.zig'
      - 'test_runner.py'
      - '.github/workflows/test-zig-parser.yml'
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'build.zig'
      - 'test_runner.py'
      - '.github/workflows/test-zig-parser.yml'

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        submodules: recursive
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install PyYAML
    
    - name: Setup Zig
      uses: goto-bus-stop/setup-zig@v2
      with:
        version: 0.14.1
    
    - name: Build Zig parser
      run: |
        zig build
    
    - name: Run unit tests
      run: |
        zig build test --summary all 2>&1 | tee unit-test-output.txt || true
    
    - name: Run YAML test suite
      run: |
        zig build test-yaml -- zig
    
    - name: Generate test report
      if: always()
      run: |
        # Capture YAML test suite results
        zig build test-yaml -- zig --verbose > test-results.txt 2>&1 || true
        
        # Add to GitHub step summary
        echo "## Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Report unit test summary from zig build test
        echo "### Unit Tests" >> $GITHUB_STEP_SUMMARY
        if [ -f unit-test-output.txt ]; then
          if grep -q "All .* tests passed" unit-test-output.txt; then
            echo "‚úÖ All tests passed!" >> $GITHUB_STEP_SUMMARY
            UNIT_TEST_SUMMARY="‚úÖ All unit tests passed"
          elif grep -q "Build Summary:" unit-test-output.txt; then
            # Extract summary from build output
            SUMMARY=$(grep "Build Summary:" unit-test-output.txt | head -1)
            echo "$SUMMARY" >> $GITHUB_STEP_SUMMARY
            UNIT_TEST_SUMMARY="$SUMMARY"
          else
            echo "Unit tests ran with issues. Check logs for details." >> $GITHUB_STEP_SUMMARY
            UNIT_TEST_SUMMARY="Unit tests: check logs for details"
          fi
        else
          echo "Unit tests were not run." >> $GITHUB_STEP_SUMMARY
          UNIT_TEST_SUMMARY="Unit tests: not run"
        fi
        echo "UNIT_TEST_SUMMARY=$UNIT_TEST_SUMMARY" >> $GITHUB_ENV
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Report YAML test suite
        echo "### YAML Test Suite" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        tail -20 test-results.txt >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        
        # Extract pass/fail counts and test lists for PR comment
        PASSING=$(grep "Passing:" test-results.txt | awk '{print $2, $3}')
        FAILING=$(grep "Failing:" test-results.txt | awk '{print $2}')
        echo "PASSING=$PASSING" >> $GITHUB_ENV
        echo "FAILING=$FAILING" >> $GITHUB_ENV
        
        # Extract failing test names
        echo "FAILING_TESTS<<EOF" >> $GITHUB_ENV
        grep "^  - " test-results.txt | head -20 >> $GITHUB_ENV
        echo "EOF" >> $GITHUB_ENV
        
        # No separate failing unit tests extraction since we use zig build test
        echo "FAILING_UNIT_TESTS<<EOF" >> $GITHUB_ENV
        echo "EOF" >> $GITHUB_ENV
        
        # Get baseline passing tests (from main branch)
        echo "BASELINE_PASSING=397" >> $GITHUB_ENV
    
    - name: Comment PR with results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const passing = process.env.PASSING || 'N/A';
          const failing = process.env.FAILING || 'N/A';
          const failingTests = process.env.FAILING_TESTS || '';
          const unitTestSummary = process.env.UNIT_TEST_SUMMARY || 'Unit tests: not run';
          const failingUnitTests = process.env.FAILING_UNIT_TESTS || '';
          const baseline = parseInt(process.env.BASELINE_PASSING || '397');
          const currentPassing = parseInt(passing.split(' ')[0]) || 0;
          const improvement = currentPassing - baseline;
          
          let statusEmoji = '‚úÖ';
          let statusText = 'All tests passing!';
          
          if (failing !== '0' && failing !== 'N/A') {
            if (currentPassing < baseline) {
              statusEmoji = '‚ùå';
              statusText = `Regression detected! ${baseline - currentPassing} fewer tests passing than baseline.`;
            } else if (currentPassing > baseline) {
              statusEmoji = 'üöÄ';
              statusText = `Progress! ${improvement} more tests passing than baseline.`;
            } else {
              statusEmoji = 'üìä';
              statusText = 'No change from baseline.';
            }
          }
          
          let commentBody = `## ${statusEmoji} Test Results
          
          ${statusText}
          
          ### Unit Tests
          ${unitTestSummary}`;
          
          if (failingUnitTests.trim()) {
            commentBody += `\n\n**Failing Unit Tests:**\n${failingUnitTests}`;
          }
          
          commentBody += `\n\n### YAML Test Suite
          - **Passing**: ${passing}
          - **Failing**: ${failing}
          - **Baseline**: ${baseline} passing`;
          
          if (improvement > 0) {
            commentBody += `\n- **Improvement**: +${improvement} tests now passing! üéâ`;
          }
          
          if (failingTests.trim()) {
            commentBody += `\n\n### Failing Tests\n${failingTests}`;
          }
          
          // Add a hidden marker to identify our bot comments
          commentBody += '\n\n<!-- yaml-test-suite-results -->';
          
          // Find existing comment
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          
          const botComment = comments.find(comment => 
            comment.body.includes('<!-- yaml-test-suite-results -->')
          );
          
          if (botComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: commentBody
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: commentBody
            });
          }
    
    - name: Check test threshold
      run: |
        # Extract the number of passing tests
        PASS_COUNT=$(grep "Passing:" test-results.txt | awk '{print $2}')
        
        # Minimum threshold (current baseline)
        MIN_PASSING=397
        
        if [ "$PASS_COUNT" -lt "$MIN_PASSING" ]; then
          echo "‚ùå Test regression detected!"
          echo "Expected at least $MIN_PASSING passing tests, but only $PASS_COUNT passed."
          exit 1
        else
          echo "‚úÖ Tests passed threshold: $PASS_COUNT/$MIN_PASSING"
        fi